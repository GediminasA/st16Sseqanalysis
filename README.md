# 16S OTDN amplification analysis

## Description
Purpose of the work flow is to run analysis of 16S data generated by using the samole preparation kit based on OTDN technology

## Dependencies

* `miniconda3 `


This workflow has quite a lot of dependancies. The best way to handle them is to use cona.
please directly to the step 6 of the Workflow setup.

## Workflow setup

1. Install `conda`:
```bash
   wget -P miniconda https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh &&
   chmod 755 ./miniconda/Miniconda3-latest-Linux-x86_64.sh &&
   ./miniconda/Miniconda3-latest-Linux-x86_64.sh
```

2. Add path of `miniconda` to `.bashrc` if not selected option to add automatically during installation:
```bash
   cd ~/ && pth=$(pwd) &&
   echo "PATH=$PATH:$pth/miniconda3/bin" >> ~/.bashrc
```

3. Install mamba frontend for conda. This helps to handle dependancies installation.
```bash
    conda install -c conda-forge mamba
```

4. Create your `conda` environment:
 ```bash
    mamba env create -f envs/main.yaml -n 16s4otdn
 ```

5. Activate created environment:
```bash
    source activate 16s4otdn
```

6. Run the small scale analysis and a set of tests:
The workflow uses an singularity image. Before running the tests or analyses you must indicate a mounting point for singularity. In other words you must indicate what lowest level directories can be accessed by the workflow. for the example below we allow workflow to access /mnt/beegfs directory.
```bash
    cd testing
    ./run_tests.py --singularity-mount-point /mnt/beegfs
```

## Example analysis

* Run `snakemake` to extyract examplary raw files:
```bash
   #Presume that 12 threads are available (option -j 12) and you allow to accsess /mnt/beegfs
   #Prepare the testing dataset:
   export SINGULARITY_BINDPATH="/mnt/beegfs" ; snakemake --use-conda --conda-frontend mamba --configfile testing/testing.yaml -j 12  extract_testing_file
```
* Run `snakemake` to perform analysis itself:
```bash
   #Presume that 12 threads are available (option -j 12) and you allow to accsess /mnt/beegfs
   export SINGULARITY_BINDPATH="/mnt/beegfs" ; snakemake --configfile configs/example.yaml -j 12 --use-conda --conda-frontend mamba 
   # An example with cluster
   export SINGULARITY_BINDPATH="/mnt/beegfs" ; snakemake --configfile configs/example.yaml --use-conda --conda-frontend mamba --cluster "qsub -V -pe smp {threads} -N {cluster.name} -p {cluster.priority} -e {cluster.error} -o {cluster.output} -cwd" -j 96 --cluster-config cluster.json
```

This would run an analysis on a small dataset matching simulated data matching Zymo standard (https://www.zymoresearch.com/collections/zymobiomics-microbial-community-standards/products/zymobiomics-microbial-community-dna-standard). 
The workflow is under intensive development  - expected output files are changing constantly.

## Notes for developers:
1. The workflow would automatically download the required singularity container. However due to overhead of inner snakemake handling and bugs in snakemake preventing usage of conda and singularity at the same time the singularity was used directly. Therefore the snakemake guidelines for singularity usage do not apply.
2. The files for further development:
out/16S_having_reads/*mergd.fastq.gz - the cleaned up trimmed 16S reads
3. some used programs are non deterministic without ability to use set  random seed. This complicatesintegration tests.



